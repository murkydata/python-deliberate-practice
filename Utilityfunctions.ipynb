{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Utilityfunctions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9GXXL6fxMDMbkHNikn2um",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murkydata/python-deliberate-practice/blob/master/Utilityfunctions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLRRSoiLpWWV"
      },
      "source": [
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "# from imdbUtils import *\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def getSoup(url):\n",
        "    \"\"\"\n",
        "    Utility function which takes a url and returns a Soup object.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    return soup\n",
        "\n",
        "def minMax(a):\n",
        "    '''Returns the index of negative and positive review.'''\n",
        "    \n",
        "    # get the index of least rated user review\n",
        "    minpos = a.index(min(a))\n",
        "    \n",
        "    # get the index of highest rated user review\n",
        "    maxpos = a.index(max(a))\n",
        "    \n",
        "    return minpos, maxpos\n",
        "\n",
        "def getReviews(soup):\n",
        "    '''Function returns a negative and positive review for each movie.'''\n",
        "    \n",
        "    # get a list of user ratings\n",
        "    user_review_ratings = [tag.previous_element for tag in \n",
        "                           soup.find_all('span', attrs={'class': 'point-scale'})]\n",
        "    \n",
        "    \n",
        "    # find the index of negative and positive review\n",
        "    n_index, p_index = minMax(list(map(int, user_review_ratings)))\n",
        "    \n",
        "    \n",
        "    # get the review tags\n",
        "    user_review_list = soup.find_all('a', attrs={'class':'title'})\n",
        "    \n",
        "    \n",
        "    # get the negative and positive review tags\n",
        "    n_review_tag = user_review_list[n_index]\n",
        "    p_review_tag = user_review_list[p_index]\n",
        "    \n",
        "    # return the negative and positive review link\n",
        "    n_review_link = \"https://www.imdb.com\" + n_review_tag['href']\n",
        "    p_review_link = \"https://www.imdb.com\" + p_review_tag['href']\n",
        "    \n",
        "    return n_review_link, p_review_link\n",
        "\n",
        "def getReviewText(review_url):\n",
        "    '''Returns the user review text given the review url.'''\n",
        "    \n",
        "    # get the review_url's soup\n",
        "    soup = getSoup(review_url)\n",
        "    \n",
        "    # find div tags with class text show-more__control\n",
        "    tag = soup.find('div', attrs={'class': 'text show-more__control'})\n",
        "    \n",
        "    return tag.getText()\n",
        "\n",
        "def getMovieTitle(review_url):\n",
        "    '''Returns the movie title from the review url.'''\n",
        "    \n",
        "    # get the review_url's soup\n",
        "    soup = getSoup(review_url)\n",
        "    \n",
        "    # find h1 tag\n",
        "    tag = soup.find('h1')\n",
        "    \n",
        "    return list(tag.children)[1].getText()\n",
        "\n",
        "def getNounChunks(user_review):\n",
        "    \n",
        "    # create the doc object\n",
        "    doc = nlp(user_review)\n",
        "    \n",
        "    # get a list of noun_chunks\n",
        "    noun_chunks = list(doc.noun_chunks)\n",
        "    \n",
        "    # convert noun_chunks from span objects to strings, otherwise it won't pickle\n",
        "    noun_chunks_strlist = [chunk.text for chunk in noun_chunks]\n",
        "    \n",
        "    return noun_chunks_strlist\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPk5rijOvBuM"
      },
      "source": [
        "url = '''https://www.imdb.com/search/title/?title_type=feature&user_rating=4.0,10.\n",
        "            0&num_votes=50000,&genres=romance&view=simple&sort=user_rating,desc&count=150'''\n",
        "\n",
        "def getSoup(url):\n",
        "    \"\"\"\n",
        "    Utility function which takes a url and returns a Soup object.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "   \n",
        "    return soup\n",
        "\n",
        "# get the soup object for main api url   \n",
        "movies_soup = getSoup(url) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syaZQINOrhzp",
        "outputId": "b8aaf375-623a-4673-d91b-726f3444170b"
      },
      "source": [
        "# find all a-tags with class:None\n",
        "movie_tags = movies_soup.find_all('a', attrs={'class': None})\n",
        "\n",
        "# filter the a-tags to get just the titles\n",
        "movie_tags = [tag.attrs['href'] for tag in movie_tags \n",
        "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
        "\n",
        "# remove duplicate links\n",
        "movie_tags = list(dict.fromkeys(movie_tags))\n",
        "\n",
        "# print(\"There are a total of \" + str(len(movie_tags)) + \" movie titles\")\n",
        "# print(\"Displaying 10 titles\")\n",
        "movie_tags[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are a total of 150 movie titles\n",
            "Displaying 10 titles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/title/tt0109830/',\n",
              " '/title/tt0118799/',\n",
              " '/title/tt0095765/',\n",
              " '/title/tt0034583/',\n",
              " '/title/tt0027977/',\n",
              " '/title/tt0021749/',\n",
              " '/title/tt5311514/',\n",
              " '/title/tt0338013/',\n",
              " '/title/tt0211915/',\n",
              " '/title/tt0119217/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x99INChGrwXU",
        "outputId": "d7c67fc8-e586-45a0-c2ec-a1fff4cb933e"
      },
      "source": [
        "# movie links\n",
        "base_url = \"https://www.imdb.com\"\n",
        "movie_links = [base_url + tag + 'reviews' for tag in movie_tags]\n",
        "print(\"There are a total of \" + str(len(movie_links)) + \" movie user reviews\")\n",
        "print(\"Displaying 10 user reviews links\")\n",
        "movie_links[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are a total of 150 movie user reviews\n",
            "Displaying 10 user reviews links\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.imdb.com/title/tt0109830/reviews',\n",
              " 'https://www.imdb.com/title/tt0118799/reviews',\n",
              " 'https://www.imdb.com/title/tt0095765/reviews',\n",
              " 'https://www.imdb.com/title/tt0034583/reviews',\n",
              " 'https://www.imdb.com/title/tt0027977/reviews',\n",
              " 'https://www.imdb.com/title/tt0021749/reviews',\n",
              " 'https://www.imdb.com/title/tt5311514/reviews',\n",
              " 'https://www.imdb.com/title/tt0338013/reviews',\n",
              " 'https://www.imdb.com/title/tt0211915/reviews',\n",
              " 'https://www.imdb.com/title/tt0119217/reviews']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aBDm4P8tzr1"
      },
      "source": [
        "Step 4: For each of the movie reviews link, get a positive user review link and a negative movie review link.\n",
        "Now that we have obtained the user reviews link for each of the 250 movies, our next task is to get the links for one positive and one negative user review link.\n",
        "\n",
        "The function getReviews() returns a tuple of positive and negative user review links for each movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yziEagNRtqnp",
        "outputId": "8cd20049-c203-4102-be43-12b31d18c01e"
      },
      "source": [
        "# get a list of soup objects\n",
        "movie_soups = [getSoup(link) for link in movie_links]\n",
        "\n",
        "# get all 500 movie review links\n",
        "movie_review_list = [getReviews(movie_soup) for movie_soup in movie_soups]\n",
        "\n",
        "movie_review_list = list(itertools.chain(*movie_review_list))\n",
        "print(len(movie_review_list))\n",
        "\n",
        "print(\"There are a total of \" + str(len(movie_review_list)) + \" individual movie reviews\")\n",
        "print(\"Displaying 10 reviews\")\n",
        "movie_review_list[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "There are a total of 300 individual movie reviews\n",
            "Displaying 10 reviews\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.imdb.com/review/rw3472550/',\n",
              " 'https://www.imdb.com/review/rw1088679/',\n",
              " 'https://www.imdb.com/review/rw1078552/',\n",
              " 'https://www.imdb.com/review/rw0409131/',\n",
              " 'https://www.imdb.com/review/rw2860182/',\n",
              " 'https://www.imdb.com/review/rw1024609/',\n",
              " 'https://www.imdb.com/review/rw5081531/',\n",
              " 'https://www.imdb.com/review/rw0026277/',\n",
              " 'https://www.imdb.com/review/rw0015336/',\n",
              " 'https://www.imdb.com/review/rw3431894/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4pmvaB7u1nb"
      },
      "source": [
        "# Construct a dataframe\n",
        "# Finally, a dataframe is constructed using these results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f4ZhXpFxZWL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LK6CiAgruZX"
      },
      "source": [
        "# get review text from the review link\n",
        "review_texts = [getReviewText(url) for url in movie_review_list]\n",
        "\n",
        "# get movie name from the review link\n",
        "movie_titles = [getMovieTitle(url) for url in movie_review_list]\n",
        "\n",
        "# label each review with negative or positive\n",
        "review_sentiment = np.array(['negative', 'positive'] * (len(movie_review_list)//2))\n",
        "\n",
        "# construct a dataframe\n",
        "df = pd.DataFrame({'movie': movie_titles, 'user_review_permalink': movie_review_list,\n",
        "             'user_review': review_texts, 'sentiment': review_sentiment})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "jd-7GyqcyzJP",
        "outputId": "1b8621f1-1670-4cbc-c6c3-7086c59fed2d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie</th>\n",
              "      <th>user_review_permalink</th>\n",
              "      <th>user_review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forrest Gump</td>\n",
              "      <td>https://www.imdb.com/review/rw3472550/</td>\n",
              "      <td>I remember John Byner, the stand-up comic and ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forrest Gump</td>\n",
              "      <td>https://www.imdb.com/review/rw1088679/</td>\n",
              "      <td>When I first saw this movie I didn't appreciat...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Life Is Beautiful</td>\n",
              "      <td>https://www.imdb.com/review/rw1078552/</td>\n",
              "      <td>There are a small handful of reviewers who are...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Life Is Beautiful</td>\n",
              "      <td>https://www.imdb.com/review/rw0409131/</td>\n",
              "      <td>I am surprised about the negative comments tha...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cinema Paradiso</td>\n",
              "      <td>https://www.imdb.com/review/rw2860182/</td>\n",
              "      <td>Don't approach the movie with your logic part ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               movie  ... sentiment\n",
              "0       Forrest Gump  ...  negative\n",
              "1       Forrest Gump  ...  positive\n",
              "2  Life Is Beautiful  ...  negative\n",
              "3  Life Is Beautiful  ...  positive\n",
              "4    Cinema Paradiso  ...  negative\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rmyj1xl6_oo"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "all_phrase =[]\n",
        "for text in df.user_review:\n",
        "  doc = nlp(text)\n",
        "  all_phrase.append([chunk.text for chunk in doc.noun_chunks]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bsyxoXrDdTH"
      },
      "source": [
        "doc = nlp(\"I have a red car\")\n",
        "# doc.noun_chunks is a generator that yields spans\n",
        "[chunk.text for chunk in doc.noun_chunks]\n",
        "# ['I', 'a red car']\n",
        "df['Tokens'] = all_phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Cdia-8FzQB"
      },
      "source": [
        "## USING NLTK Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyPWuCMCCugj",
        "outputId": "55775a55-c5a7-47c5-96b1-8f39abb2fae2"
      },
      "source": [
        "import nltk\n",
        "import pprint\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        " \n",
        "def preprocess(doc):\n",
        "    sentences = nltk.sent_tokenize(doc)\n",
        "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
        "    return sentences\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0fulVRO-avS"
      },
      "source": [
        "token_text = [ preprocess(text) for text in df.user_review ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnwEaYwKHu_C",
        "outputId": "bde90005-e702-408c-bb48-4f2934affc7f"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk import RegexpParser\n",
        "from nltk import Tree\n",
        "import pandas as pd\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
        "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
        "    continuous_chunk = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for subtree in chunked:\n",
        "        if type(subtree) == Tree:\n",
        "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
        "        elif current_chunk:\n",
        "            named_entity = \" \".join(current_chunk)\n",
        "            if named_entity not in continuous_chunk:\n",
        "                continuous_chunk.append(named_entity)\n",
        "                current_chunk = []\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return continuous_chunk\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK5M9A-pH4DH"
      },
      "source": [
        "NP_tokens = df['user_review'].apply(lambda sent:get_continuous_chunks((sent)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1clLhVlIcgD"
      },
      "source": [
        "df['NP Chunk'] = NP_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oiVvfeCKK_hu",
        "outputId": "0fd539c6-e944-48da-b3d6-3fe1654feca5"
      },
      "source": [
        "df.sample(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie</th>\n",
              "      <th>user_review_permalink</th>\n",
              "      <th>user_review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>NP Chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Your Name.</td>\n",
              "      <td>https://www.imdb.com/review/rw4180336/</td>\n",
              "      <td>This anime is just superb. It is one of those ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[This anime, It, those moments, a rare absorbi...</td>\n",
              "      <td>[JJ Abrams, Hollywood, Kimi No Na Wa, Dallas T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
              "      <td>https://www.imdb.com/review/rw1020113/</td>\n",
              "      <td>Joel (Jim Carrey) is a rather milquetoast man ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[Joel, Jim Carrey, a rather milquetoast man, w...</td>\n",
              "      <td>[Joel, Jim Carrey, Kate, Clementine, Lacuna, J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Wild Strawberries</td>\n",
              "      <td>https://www.imdb.com/review/rw1113924/</td>\n",
              "      <td>This is a film school movie; one of the greate...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[a film school movie, the experts, I, the play...</td>\n",
              "      <td>[English, Wild Strawberries, Wild Strawberries...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Big Fish</td>\n",
              "      <td>https://www.imdb.com/review/rw1583793/</td>\n",
              "      <td>Subtle, delicate, touching and fascinating ple...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[Subtle, delicate, touching and fascinating pl...</td>\n",
              "      <td>[Subtle, Tom Burton, Christamas Eve, Ewan Mc G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Casablanca</td>\n",
              "      <td>https://www.imdb.com/review/rw5081531/</td>\n",
              "      <td>I say a 'simple' story because I am writing th...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[I, a 'simple' story, I, this piece, almost 77...</td>\n",
              "      <td>[Bogart, Bergman]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>The Last of the Mohicans</td>\n",
              "      <td>https://www.imdb.com/review/rw1818234/</td>\n",
              "      <td>My all time favorite film. Still gives me chil...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[My all time favorite film, me, chills, It, th...</td>\n",
              "      <td>[Mohicans, French, Indian, Michael Mann, Frenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Moonrise Kingdom</td>\n",
              "      <td>https://www.imdb.com/review/rw2614681/</td>\n",
              "      <td>Let's try to understand the miracle I have jus...</td>\n",
              "      <td>positive</td>\n",
              "      <td>['s, the miracle, I, Director Wes Anderson, hi...</td>\n",
              "      <td>[Director Wes Anderson, Summer, Norton, Willis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>Stardust</td>\n",
              "      <td>https://www.imdb.com/review/rw1708237/</td>\n",
              "      <td>Why are the previews so blah for a movie that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[the previews, so blah, a movie, Everyone, wha...</td>\n",
              "      <td>[Princess Bride, Labyrinth, Robert DeNiro, Cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>500 Days of Summer</td>\n",
              "      <td>https://www.imdb.com/review/rw6468527/</td>\n",
              "      <td>LiarsMisandristsHosMisanthropes and\\nCheats</td>\n",
              "      <td>positive</td>\n",
              "      <td>[LiarsMisandristsHosMisanthropes, Cheats]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Amour</td>\n",
              "      <td>https://www.imdb.com/review/rw2705833/</td>\n",
              "      <td>What introduction could this film possibly req...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[What introduction, this film, Any film enthus...</td>\n",
              "      <td>[Haneke, Amour, Palme, Cannes, Haneke Amour, H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>A Single Man</td>\n",
              "      <td>https://www.imdb.com/review/rw5388060/</td>\n",
              "      <td>I like to iron my business shirts and shine my...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[I, my business shirts, my shoes, a couple, ho...</td>\n",
              "      <td>[Ford, George, Oxford, Shigeru Umeyabashi, Tom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>Fruitvale Station</td>\n",
              "      <td>https://www.imdb.com/review/rw2848162/</td>\n",
              "      <td>First off, let me say that if this movie wasn'...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[me, this movie, a real life story, the BART o...</td>\n",
              "      <td>[BART, Oprha, Hollywood, Hollywood Which]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     movie  ...                                           NP Chunk\n",
              "12                              Your Name.  ...  [JJ Abrams, Hollywood, Kimi No Na Wa, Dallas T...\n",
              "14   Eternal Sunshine of the Spotless Mind  ...  [Joel, Jim Carrey, Kate, Clementine, Lacuna, J...\n",
              "30                       Wild Strawberries  ...  [English, Wild Strawberries, Wild Strawberries...\n",
              "78                                Big Fish  ...  [Subtle, Tom Burton, Christamas Eve, Ewan Mc G...\n",
              "6                               Casablanca  ...                                  [Bogart, Bergman]\n",
              "215               The Last of the Mohicans  ...  [Mohicans, French, Indian, Michael Mann, Frenc...\n",
              "155                       Moonrise Kingdom  ...  [Director Wes Anderson, Summer, Norton, Willis...\n",
              "241                               Stardust  ...  [Princess Bride, Labyrinth, Robert DeNiro, Cha...\n",
              "197                     500 Days of Summer  ...                                                 []\n",
              "115                                  Amour  ...  [Haneke, Amour, Palme, Cannes, Haneke Amour, H...\n",
              "232                           A Single Man  ...  [Ford, George, Oxford, Shigeru Umeyabashi, Tom...\n",
              "288                      Fruitvale Station  ...          [BART, Oprha, Hollywood, Hollywood Which]\n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gtdX0U5HV3j"
      },
      "source": [
        "## Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FsotKjNqUzB"
      },
      "source": [
        ""
      ]
    }
  ]
}